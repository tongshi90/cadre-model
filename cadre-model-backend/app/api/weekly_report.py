from flask import request
from app.api import weekly_report_bp
from app.utils.helpers import success_response, error_response


@weekly_report_bp.route('/weekly-report/data', methods=['GET'])
def get_weekly_report_data():
    """è·å–å‘¨æŠ¥æ•°æ®ç”¨äºAIåˆ†æ"""
    from app.models.weekly_report import WeeklyReport
    from app import db

    try:
        # è·å–æ‰€æœ‰å‘¨æŠ¥æ•°æ®
        reports = WeeklyReport.query.order_by(WeeklyReport.created_at.desc()).all()

        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºæ•°æ®
        if not reports:
            return success_response([], 'è·å–æˆåŠŸ')

        # è½¬æ¢ä¸ºINSERTè¯­å¥æ ¼å¼ä¾›AIä½¿ç”¨
        insert_statements = []
        for report in reports:
            stmt = f"INSERT INTO weekly_report (content, created_at) VALUES ('{report.content.replace(chr(39), chr(39)+chr(39))}', '{report.created_at.strftime('%Y-%m-%d %H:%M:%S')}');"
            insert_statements.append(stmt)

        # åŒæ—¶è¿”å›åŸå§‹æ•°æ®
        report_data = [report.to_dict() for report in reports]

        return success_response({
            'insert_statements': insert_statements,
            'reports': report_data
        }, 'è·å–æˆåŠŸ')

    except Exception as e:
        return error_response(f'è·å–å¤±è´¥: {str(e)}', 500)


def estimate_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡
    ä¸­æ–‡ï¼šçº¦1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡ï¼šçº¦4å­—ç¬¦/token
    è¿™é‡Œä½¿ç”¨ç®€åŒ–ä¼°ç®—ï¼šä¸­è‹±æ–‡æ··åˆçº¦2å­—ç¬¦/token
    """
    return len(text) // 2


def check_token_limit(messages: list, model_name: str, model_max_tokens: int) -> dict:
    """
    æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦è¶…è¿‡æ¨¡å‹çš„tokené™åˆ¶

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        model_name: æ¨¡å‹åç§°
        model_max_tokens: æ¨¡å‹æœ€å¤§tokenæ•°

    Returns:
        æ£€æŸ¥ç»“æœå­—å…¸
    """
    # è®¡ç®—æ‰€æœ‰æ¶ˆæ¯çš„æ€»tokenæ•°
    total_tokens = 0
    breakdown = []

    for msg in messages:
        content = msg.get('content', '')
        msg_tokens = estimate_tokens(content)
        total_tokens += msg_tokens
        breakdown.append({
            'role': msg.get('role'),
            'tokens': msg_tokens,
            'content_length': len(content)
        })

    # è®¡ç®—tokenä½¿ç”¨ç‡
    usage_rate = (total_tokens / model_max_tokens) * 100

    # é¢„ç•™è¾“å‡ºç©ºé—´ï¼ˆçº¦2048 tokensï¼‰
    reserved_output = 2048
    available_for_input = model_max_tokens - reserved_output

    return {
        'model': model_name,
        'model_max_tokens': model_max_tokens,
        'estimated_input_tokens': total_tokens,
        'usage_rate': f'{usage_rate:.2f}%',
        'will_truncate': total_tokens > available_for_input,
        'available_tokens': available_for_input,
        'breakdown': breakdown,
        'message': (
            f'âš ï¸ Tokenè¶…é™è­¦å‘Šï¼å½“å‰ä¼°ç®—{total_tokens} tokensï¼Œ'
            f'è¶…è¿‡å®‰å…¨é˜ˆå€¼{available_for_input} tokensï¼Œå¯èƒ½è¢«æˆªæ–­ï¼'
            if total_tokens > available_for_input
            else f'âœ… Tokenæ­£å¸¸ã€‚å½“å‰{total_tokens} tokensï¼Œ'
            f'ä½¿ç”¨ç‡{usage_rate:.1f}%ï¼Œå®‰å…¨é˜ˆå€¼{available_for_input} tokensã€‚'
        )
    }


@weekly_report_bp.route('/weekly-report/ai-chat', methods=['POST'])
def ai_chat():
    """AIå¯¹è¯æ¥å£"""
    from app.models.weekly_report import WeeklyReport
    from app import db

    try:
        data = request.get_json()
        user_message = data.get('message')
        conversation_history = data.get('history', [])

        if not user_message:
            return error_response('ç¼ºå°‘æ¶ˆæ¯å†…å®¹', 400)

        # è·å–å‘¨æŠ¥æ•°æ®
        reports = WeeklyReport.query.order_by(WeeklyReport.created_at.desc()).all()

        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›æç¤º
        if not reports:
            return success_response({
                'reply': 'æš‚æ— å‘¨æŠ¥æ•°æ®ï¼Œè¯·å…ˆæ·»åŠ å‘¨æŠ¥æ•°æ®ã€‚'
            }, 'å¯¹è¯æˆåŠŸ')

        # æ„å»ºä¸Šä¸‹æ–‡æ•°æ®æ—¶æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯ï¼ˆæäº¤äººã€æ—¶é—´ï¼‰
        context_parts = []
        for i, report in enumerate(reports, 1):
            # è·å–æäº¤äººä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            submitter = getattr(report, 'submitter', '')
            created_at = report.created_at.strftime('%Y-%m-%d') if report.created_at else ''
            meta_info = f"ã€å‘¨æŠ¥{i}"
            if submitter:
                meta_info += f" | æäº¤äºº: {submitter}"
            if created_at:
                meta_info += f" | æ—¶é—´: {created_at}"
            meta_info += "ã€‘\n"
            context_parts.append(f"{meta_info}{report.content}\n")

        context_data = "\n".join(context_parts)

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ ç°åœ¨éœ€è¦æ‰®æ¼”ä¸€ä¸ªåŸºäºå¹²éƒ¨å‘¨æŠ¥æ•°æ®çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œæ ¸å¿ƒè§„åˆ™å¦‚ä¸‹ï¼š

ã€æ•°æ®æ¥æºç‰¹æ€§ã€‘
ä½ å°†è·å¾—è‹¥å¹²æ¡å‘¨æŠ¥è®°å½•ï¼Œæ¯æ¡è®°å½•åŒ…å«æäº¤äººã€æäº¤æ—¶é—´å’Œå‘¨æŠ¥å†…å®¹ã€‚

âš ï¸ é‡è¦ï¼šå‘¨æŠ¥å…·æœ‰æ—¶æ•ˆæ€§å’Œè¿ç»­æ€§
- åŒä¸€äº‹é¡¹å¯èƒ½åœ¨ä¸åŒå‘¨æŠ¥ä¸­å¤šæ¬¡å‡ºç°ï¼Œä»£è¡¨ä¸åŒé˜¶æ®µçš„è¿›å±•
- ä¾‹å¦‚ï¼šç¬¬ä¸€å‘¨"é¡¹ç›®Aå®Œæˆ20%"ï¼Œç¬¬äºŒå‘¨"é¡¹ç›®Aå®Œæˆ80%"ï¼Œè¿™æ˜¯åŒä¸€äº‹é¡¹çš„è¿›åº¦æ›´æ–°ï¼Œè€Œéé‡å¤
- å›ç­”é—®é¢˜æ—¶éœ€è¦è¯†åˆ«å¹¶åˆå¹¶è¿™äº›è¿ç»­çš„è¿›åº¦ä¿¡æ¯ï¼Œå±•ç°å®Œæ•´çš„æ—¶é—´çº¿

ã€å›ç­”è¦æ±‚ã€‘
1. ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œä¸è¦è¯´æ˜ä»å“ªæ¡å‘¨æŠ¥è·å–çš„ä¿¡æ¯ï¼Œä¸è¦å±•ç¤ºåˆ†æè¿‡ç¨‹
2. å¯ä»¥å›ç­”çš„é—®é¢˜ç±»å‹åŒ…æ‹¬ä½†ä¸é™äºï¼š
   - æŸå¹²éƒ¨çš„é¡¹ç›®è¿›åº¦ã€å·¥ä½œå†…å®¹ã€é£é™©ç‚¹
   - æŸé¡¹ç›®çš„è´Ÿè´£äººã€è¿›å±•æƒ…å†µ
   - æŸæ—¶é—´æ®µçš„å·¥ä½œå®‰æ’
   - å„é¡¹å·¥ä½œçš„å®Œæˆæƒ…å†µ
   - æŸäº‹é¡¹çš„å®Œæ•´è¿›å±•æ—¶é—´çº¿

3. æ™ºèƒ½å¤„ç†è¿ç»­ä¿¡æ¯ï¼š
   - è¯†åˆ«åŒä¸€äº‹é¡¹åœ¨ä¸åŒå‘¨æŠ¥ä¸­çš„è¿›åº¦æ›´æ–°
   - æŒ‰æ—¶é—´é¡ºåºåˆå¹¶ä¿¡æ¯ï¼Œå±•ç°å®Œæ•´è¿›å±•
   - å¯¹äºç”¨æˆ·è¯¢é—®çš„äº‹é¡¹ï¼Œæä¾›ä»å¼€å§‹åˆ°å½“å‰çš„å®Œæ•´æ—¶é—´çº¿
   - é¿å…ç®€å•ç½—åˆ—é‡å¤ä¿¡æ¯ï¼Œè€Œæ˜¯æç‚¼å‡ºäº‹é¡¹çš„å‘å±•è„‰ç»œ

4. è‹¥ç”¨æˆ·é—®é¢˜æ¶‰åŠå¤šä¸ªå¹²éƒ¨æˆ–å¤šä¸ªé¡¹ç›®ï¼Œéœ€åˆ†ç»´åº¦æ¸…æ™°ç½—åˆ—ï¼Œé€»è¾‘è¿è´¯

5. è‹¥é—®é¢˜åœ¨å‘¨æŠ¥å†…å®¹ä¸­æ— å¯¹åº”ä¿¡æ¯ï¼Œç›´æ¥å›å¤"æœªæŸ¥è¯¢åˆ°ç›¸å…³å‘¨æŠ¥ä¿¡æ¯"

ã€æ ¼å¼è§„èŒƒã€‘
- å›ç­”ç®€æ´æ˜äº†ï¼Œç›´æ¥å‘ˆç°ç»“æœ
- ä¼˜å…ˆä½¿ç”¨æ¡ç›®åŒ–è¡¨è¿°
- æ¶‰åŠæ—¶é—´çš„å†…å®¹ï¼Œä¿æŒåŸæ–‡æ ¼å¼æˆ–è½¬æ¢ä¸ºæ˜“è¯»æ ¼å¼
- å±•ç°äº‹é¡¹è¿›å±•æ—¶ï¼Œå»ºè®®ä½¿ç”¨æ—¶é—´çº¿æˆ–è¿›åº¦æ¡çš„æ–¹å¼å‘ˆç°"""

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {
                "role": "system",
                "content": f"{system_prompt}\n\nã€å‘¨æŠ¥æ•°æ®ä¸Šä¸‹æ–‡ã€‘\n{context_data}"
            }
        ]

        # æ·»åŠ å¯¹è¯å†å²ï¼ˆä»…ä¿ç•™æœ€è¿‘çš„5è½®å¯¹è¯ä»¥æ§åˆ¶tokenä½¿ç”¨ï¼‰
        recent_history = conversation_history[-10:] if len(conversation_history) > 10 else conversation_history
        for msg in recent_history:
            if msg.get('role') in ['user', 'assistant']:
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": user_message
        })

        # Tokenæ£€æŸ¥ï¼ˆQwen2.5-14B-Instruct æœ€å¤§æ”¯æŒ 32768 tokensï¼‰
        token_check = check_token_limit(messages, 'Qwen/Qwen2.5-14B-Instruct', 32768)

        # æ‰“å°tokenæ£€æŸ¥ç»“æœåˆ°console
        print("=" * 60)
        print("ğŸ“Š Token æ£€æŸ¥æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ¨¡å‹: {token_check['model']}")
        print(f"æ¨¡å‹æœ€å¤§Token: {token_check['model_max_tokens']}")
        print(f"ä¼°ç®—è¾“å…¥Token: {token_check['estimated_input_tokens']}")
        print(f"ä½¿ç”¨ç‡: {token_check['usage_rate']}")
        print(f"å¯ç”¨Token(é¢„ç•™è¾“å‡º): {token_check['available_tokens']}")
        print(f"æ˜¯å¦è¶…é™: {'âš ï¸ æ˜¯' if token_check['will_truncate'] else 'âœ… å¦'}")
        print("-" * 60)
        print("æ¶ˆæ¯è¯¦æƒ…:")
        for i, item in enumerate(token_check['breakdown'], 1):
            print(f"  [{i}] {item['role']:12} - {item['tokens']:6} tokens (å†…å®¹é•¿åº¦: {item['content_length']} å­—ç¬¦)")
        print("=" * 60)
        print(token_check['message'])
        print("=" * 60)

        # è°ƒç”¨ç¡…åŸºæµåŠ¨API
        import requests

        response = requests.post(
            'https://api.siliconflow.cn/v1/chat/completions',
            headers={
                'Content-Type': 'application/json',
                'Authorization': 'Bearer sk-pjdyzooethndmyauyzjbopafxxqogayzhjopheijtwgkgras',
            },
            json={
                'model': 'Qwen/Qwen2.5-14B-Instruct',
                'messages': messages,
                'stream': False,
            },
            timeout=60
        )

        if response.status_code != 200:
            return error_response(f'AIæœåŠ¡è¯·æ±‚å¤±è´¥: {response.status_code}', 500)

        result = response.json()
        ai_reply = result.get('choices', [{}])[0].get('message', {}).get('content', 'æ— æ³•è·å–AIå“åº”')

        return success_response({
            'reply': ai_reply
        }, 'å¯¹è¯æˆåŠŸ')

    except Exception as e:
        return error_response(f'å¯¹è¯å¤±è´¥: {str(e)}', 500)
